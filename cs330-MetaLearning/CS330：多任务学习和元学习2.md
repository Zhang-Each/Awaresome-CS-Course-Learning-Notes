# CS330：Multi-task Learning&Meta Learning2

> 本章笔记的内容主要是原课程的Lecture3，主要讲元学习问题的定义和黑盒元学习

## 元学习问题

​	  前面已经说到多任务学习和迁移学习的定义和区别，这里再复习一下，多任务学习是训练模型一次性解决多个任务，而迁移学习是将一个任务上的模型迁移到另一个任务上，主要是通过训练+微调的pipeline来完成迁移学习，这也是两种学习模式的主要区别。而元学习问题的目标是“学习如何学习”，可以从两种不同的视角来看待。

- 从机械的视角来看，深度网络可以将整个数据集读入并且可以预测新数据点的结果，那么就可以使用一个元数据集来训练网络，这个元数据集中包含很多的数据集，每一个数据集对应的任务各不相同
- 从概率的视角来看，元学习需要从一些任务中**抽取出有效的先验知识用于解决新的任务**，并且使用这些先验的知识来和新的训练数据集来学习一个新的任务的后验参数

也就是说元学习是**给定多个任务和对应的数据集进行训练，并在新的任务和新的测试集上验证效果**。

​	  元学习的一个关键假设是，所有的任务应该遵循独立同分布(IID)，也就是说我们需要完成的任务应该具有相似的结构，举几个简单的例子：

- 从不同语言的手写数字中进行手写数字识别
- 过滤不同用户的垃圾邮件
- 对世界上不同地区的物种进行一定的分类
- 让一个机器人完成各种不同的任务

### 元学习的算法概述

​	  普通的监督学习算法是从数据集$\{(x,y)_i\}$中学习出一个模型$y=f(x,\theta)$，而元监督学习算法可以表示为从由K个数据集构成的训练集$\{(x,y)_{1:K}\}$中学习出一个模型$y_{test}=h(D^{tr},x_{test},\theta)$，这就将元学习的问题归结为了函数h的设计和优化问题。

![image-20210724194509086](static/image-20210724194509086.png)

### 黑盒方法

​	  黑盒方法就是使用神经网络来训练元学习模型，我们希望能够用神经网络模型表示每个任务，即$\phi_i=f_{\theta}(D^{tr})$然后使用这些学习到的$\phi_i$(被称为learner)来预测测试任务上的效果，即$y^{ts}=g_{\phi_i}(x^{ts})$

![image-20210724195345097](static/image-20210724195345097.png)

- 和普通的监督学习模型一样，我们使用极大似然法作为训练的目标，因此目标函数可以定义为：

$$
\max _{\theta} \sum_{\mathcal{T}_{i}} \sum_{(x, y) \sim D_i^{\text {test }}} \log g_{\phi_{i}}(y \mid x)=\max _{\theta} \sum_{\mathcal{T}_{i}} \mathcal L(f_{\theta}(D_i^{tr}, D_i^{test}))
$$

- 整个训练的过程可以用下面四个步骤来表示：

![image-20210724195930906](static/image-20210724195930906.png)

- 这里训练过程中计算的loss函数是从train task的数据集中划分出来的，而不是直接用test task中的数据集
- 同时，我们训练完每个任务之后，是否需要将得到的模型的所有参数作为结果输出到test task的预测中呢？答案是否定的，我们需要将每个train task训练得到的模型有一个低维向量$h_i$来表示它的一些上下文信息并用到最终的模型中，而具体怎么使用这个学习到的$h_i$则要进一步看论文，有各种各样莫名其妙的方法。
- 总的来说这样的方法表现力比较好，可以将不同的任务中学到的信息进行组合，但是在复杂的模型中，进行优化可能会非常困难，计算量非常大。















