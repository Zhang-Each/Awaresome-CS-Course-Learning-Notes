# 论文阅读笔记32：提示学习Prompt

> 综述论文《[Pre-train, Prompt, and Predict: A Systematic Survey of
> Prompting Methods in Natural Language Processing](https://arxiv.org/abs/2107.13586》的阅读笔记，来简单了解一下去年听说很热门的Prompt是个什么东西。

## Introduction: NLP范式的变迁

NLP领域的范式(Paradigms)经过了多次的变迁，最早的时候，NLP主要依赖统计机器学习模型来解决一下完全监督的问题，这个过程主要依赖于各种各样的特征工程(Feature Engineer)来提取数据中的特征并用机器学习模型来解决问题。

第二个阶段，神经网络和深度学习被引入了NLP任务中，这种范式依然是全监督学习的形式，但是神经网络将设计模型所需做的特征工程工作改成了架构工程(Architecture Engineer)，也就是设计更合适的模型架构。前两个阶段中，NLP的模型训练主要依靠的是有效的监督信息。

第三个阶段，BERT等大规模的预训练模型的引入让NLP的范式变成了预训练和微调，我们解决NLP问题的方式就变成了用预训练好的模型，加入几个简单的层进行下游任务的微调，而这个范式中，主要的工作就变成了设计训练目标(包括预训练的目标和下游任务的目标)，很经典的预训练目标包括掩码语言模型MLM和下句预测。

而NLP范式变迁的第四个阶段就是现在很火热的提示学习Prompt，它的过程包括Pre-train, Prompt和Predict三个步骤，其中的主要工作被称为Prompt Engineer，具体是怎么样后面会细说。这里论文给出了一个表格来对比四种范式。

![image-20220119193431793](static/image-20220119193431793.png)

我们知道NLP任务主要可以分成分类，标注和生成三种，而在前两个阶段，三种任务之间不能共享语言模型的参数，而从预训练-微调这个范式开始，三种任务逐渐可以被统一到大规模的预训练模型下面共享参数。

## Prompt的基本要素

下面我们就需要来解释什么是Prompt，对于传统的NLP模型来说，我们一般接受一个输入x然后根据模型$P(y|x, \theta)$来预测模型的输出y，这里的y可以是一个标签，或者文本，或者其他的形式。而为了学习模型参数$\theta$，我们需要使用输入输出成对的数据对模型进行训练，让模型来预测这个条件概率$P(y|x, \theta)$，这是传统的有监督NLP

### Prompt的基本介绍

Prompt方法和传统方法的不同之处在于，它希望直接学习到输入数据x自身根据模型参数的概率分布$P(x,\theta)$，然后用这个概率来预测结果y，它的整个运行过程可以用下面的表格来概括：

![image-20220119203534909](static/image-20220119203534909.png)

#### 添加Prompt

Prompt的总体框架中，首先要对于输入的数据要通过一个Prompt函数将其转变为对应的Prompt，这个函数就是一个**模板**，会将输入的文本数据x填充到模板中，并且还保留了填写答案的空位。根据答案的位置可以将Prompt分成Prefix Prompt(答案位置在句子末尾)和Cloze Prompt(答案位置在句子中间)两种。

#### 答案搜索

然后我们需要定义一个答案集合Z，里面包含了若干个可能作为答案的选项(x对应的原本输出y就是正确答案)，然后我们将这些答案分别填写到Prompt中，构成一系列Filled Prompt，其中填写了正确答案的叫做Answer Prompt

然后我们在答案集合中搜索使得Prompt经过语言模型LM计算后所得到的分数最高的结果$\hat z$，即：
$$
\hat{z}=\mathrm{Search}_{z \in \mathcal{Z}} P\left(f_{\mathrm{fill }}(x^{\prime}, z\right) ; \theta)
$$
这个搜索可以是常见的argmax搜索。

#### 答案映射

最后我们需要将得分最高的答案$\hat z$变成得分最高的结果$\hat y$，对于一些任务来说，得分最高的结果可能就作为答案使用，比如语言生成类的任务，但是也有一些任务需要进行一个答案到结果的转换，比如分析句子的正负面情绪，我们可以设定答案集合为wonderful，excellent，awful等等，其中wonderful和excellent对应的结果是正面的情感，而awful则对应负面的情感，我们要将最后的不同答案的得分总结成输出结果，并输出可能概率最高的结果。这就需要建立一个从answer到result的映射。

### Prompt模型中的设计考虑

根据Prompt的基本性质，在设计Prompt模型的时候，我们有这样几个地方是需要考虑的：

- 选择不同的预训练模型，因为预训练LM根据与训练任务的不同，在不同的任务上会有不同的表现
- Prompt Engineering, 选择合适的Prompt构建方式，针对任务构建有效的Prompt
- Answer Engineering, 选择合适的答案搜索空间以及答案到结果的映射关系
- 对Prompt训练范式进行扩展
- 选择合适的训练策略

## 预训练语言模型

我们首先要选择一个合适的预训练语言模型(PLM)作为Prompt的基础，而PLM可以按照预训练策略、文本加噪声方式、注意力掩码、架构类型和应用场景进行分类，不同的PLM适合不同的场景。

### 预训练目标

不同的PLM在预训练阶段会采用不同的任务(也就是预训练目标)，常见的预训练任务有：

- 标准语言模型：采用自回归预测的方式，训练模型来预测句子中本身存在的单词，一般预测的方向都是从左到右，常见的比如预测下一个单词(Next Word Prediction)
- 降噪：这种训练目标是对标准语言模型的一种改进，它通过在输入的文本中增加噪声，并训练模型来预测原本正确的输入，这种训练目标可以细分成下面两种
  - 乱序文本重建：对输入文本加噪声，并对**噪声部分进行判断**是否有噪声
  - 全文重建：判断**整个输入文本**是否加了噪声

### 噪声函数

在降噪类的训练目标中，噪声函数是一个很重要的模型设计点，对文本加噪声的方式主要有掩码，替换，删除，打乱，旋转和拼接等等，如下表所示：

![image-20220123204758770](static/image-20220123204758770.png)

不同的加噪声方式训练出的模型适合不同的下游任务。

### 模型的表示方向

模型的表示方向指的是训练过程中模型对上下文的感知情况，具体可以分成以下两种：

- 从左到右：模型中每个单词的表示取决于它自身和它前面出现的单词，在训练过程中，每个位置的单词不能观测到位于它后面的单词。
- 双向奔赴：训练过程中单词可以感知到整个句子中所有的单词

在训练过程中实现这些表示方式需要依赖不同的mask

![image-20220123213352095](static/image-20220123213352095.png)



### 预训练方式

因此，常见的PLM根据目标，噪声函数和表示方向的不同，主要有以下几种不同的范式：

- 从左到右的语言模型
- 掩码语言模型
- 前缀语言模型
- 编码器-解码器语言模型

![image-20220123213657640](static/image-20220123213657640.png)

## 提示工程



## 答案工程



## 多提示学习



## 训练策略

